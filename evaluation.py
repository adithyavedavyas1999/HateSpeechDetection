from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import pandas as pd

# Evaluation Functions

# Function to evaluate the model's performance
def return_score(y_true, y_pred):
    """
    Calculates performance metrics for the model.
    
    Args:
    y_true: Ground truth labels (true values for the test or validation set).
    y_pred: Predicted labels (generated by the model).
    
    Returns:
    Dictionary containing:
        - Accuracy: Proportion of correctly classified samples.
        - F1 Score: Harmonic mean of precision and recall.
        - Precision: Proportion of true positives among predicted positives.
        - Recall: Proportion of true positives among actual positives.
    """
    acc = accuracy_score(y_true, y_pred)  # Calculate accuracy
    f1 = f1_score(y_true, y_pred, average="weighted")  # Calculate F1 score (weighted for imbalanced datasets)
    precision = precision_score(y_true, y_pred, average="weighted")  # Calculate precision (weighted)
    recall = recall_score(y_true, y_pred, average="weighted")  # Calculate recall (weighted)
    return {"accuracy": acc, "f1": f1, "precision": precision, "recall": recall}


# Function to plot the confusion matrix
def plot_confusion_matrix(y_true, y_pred):
    """
    Generates and displays a confusion matrix to visualize model performance.
    
    Args:
    y_true: Ground truth labels (true values for the test or validation set).
    y_pred: Predicted labels (generated by the model).
    
    Returns:
    None. Displays a normalized confusion matrix using Matplotlib.
    """
    # Create and display a confusion matrix, normalized by the number of true samples
    ConfusionMatrixDisplay.from_predictions(y_true, y_pred, normalize="true")
    plt.title("Confusion Matrix (Normalized)")  # Add a title to the confusion matrix
    plt.show()  # Display the confusion matrix


# Function to plot training loss and accuracy over epochs
def plot_loss_and_accuracy(history):
    """
    Plots training and validation loss, as well as training and validation accuracy, 
    over the epochs for a deep learning model.
    
    Args:
    history: Training history object generated by the `fit` method of a Keras model. 
             Contains loss and accuracy metrics for each epoch.
    
    Returns:
    None. Displays line plots using Matplotlib for:
        - Training and validation loss.
        - Training and validation accuracy.
    """
    # Convert history to a Pandas DataFrame for easier handling
    history_df = pd.DataFrame(history.history)

    # Plot training and validation loss over epochs
    history_df.loc[:, ['loss', 'val_loss']].plot()
    plt.title("Training and Validation Loss")  # Add a title to the plot
    plt.xlabel("Epochs")  # Label x-axis
    plt.ylabel("Loss")  # Label y-axis
    plt.grid(True)  # Add a grid for better readability
    plt.legend(["Training Loss", "Validation Loss"])  # Add a legend
    plt.show()  # Display the loss plot

    # Plot training and validation accuracy over epochs
    history_df.loc[:, ['accuracy', 'val_accuracy']].plot()
    plt.title("Training and Validation Accuracy")  # Add a title to the plot
    plt.xlabel("Epochs")  # Label x-axis
    plt.ylabel("Accuracy")  # Label y-axis
    plt.grid(True)  # Add a grid for better readability
    plt.legend(["Training Accuracy", "Validation Accuracy"])  # Add a legend
    plt.show()  # Display the accuracy plot